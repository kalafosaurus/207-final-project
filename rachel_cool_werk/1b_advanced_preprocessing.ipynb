{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c8802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Variables\n",
    "DATA_PATH = Path(\"../data/fungi-clef-2025\")\n",
    "MD_PATH = DATA_PATH / \"metadata/FungiTastic-FewShot\"\n",
    "IMAGE_PATH = DATA_PATH / \"images/FungiTastic-FewShot\"\n",
    "LABEL = \"class\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69029503",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata for each split\n",
    "md_train_val = pd.read_csv(MD_PATH / \"FungiTastic-FewShot-Train.csv\")\n",
    "# Use the validation set as the test set because it has labels\n",
    "md_test = pd.read_csv(MD_PATH / \"FungiTastic-FewShot-Val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows that are missing labels\n",
    "md_train_val = md_train_val.dropna(subset=LABEL)\n",
    "# Drop any classes that have only 1 label so we can stratify\n",
    "md_train_val = md_train_val.groupby(LABEL).filter(lambda group: len(group) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff95ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train data into training and validation\n",
    "md_train, md_val = train_test_split(md_train_val, test_size=0.20, stratify=md_train_val[LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859eab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label each split\n",
    "md_train[\"split\"] = \"train\"\n",
    "md_val[\"split\"] = \"val\"\n",
    "md_test[\"split\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c77c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all of the data together\n",
    "md_df = pd.concat([md_train, md_val, md_test])\n",
    "\n",
    "# Add the full image location for each image\n",
    "# Options for image size include 300p, 500p, 720p, fullsize\n",
    "md_df[\"image_path\"] = md_df.apply(\n",
    "    lambda row: IMAGE_PATH / f\"{'val' if row['split'] == 'test' else 'train'}/300p/{row['filename']}\", axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4019589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the class to an ID\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(md_df[\"class\"])\n",
    "md_df[\"class_label\"] = md_df[\"class\"]\n",
    "md_df[\"class_idx\"] = le.transform(md_df[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd569ac5",
   "metadata": {},
   "source": [
    "### Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6716907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "TARGET_SIZE = 224\n",
    "\n",
    "label_counts = {}\n",
    "\n",
    "for _, row in md_df.iterrows():\n",
    "    #\n",
    "    if row[\"class_idx\"] not in label_counts:\n",
    "        label_counts[row[\"class_idx\"]] = 0\n",
    "\n",
    "    if label_counts[row[\"class_idx\"]] >= 1000:\n",
    "        pass\n",
    "\n",
    "    label_counts[row[\"class_idx\"]] += 1\n",
    "\n",
    "    # Load and save the image as an array\n",
    "    img = load_img(row[\"image_path\"])\n",
    "\n",
    "    # Get original dimensions\n",
    "    original_height = tf.cast(tf.shape(img)[0], tf.float32)\n",
    "    original_width = tf.cast(tf.shape(img)[1], tf.float32)\n",
    "\n",
    "    # Calculate scaling factor to maintain aspect ratio\n",
    "    height_scale = TARGET_SIZE / original_height\n",
    "    width_scale = TARGET_SIZE / original_width\n",
    "    scale = tf.minimum(height_scale, width_scale)\n",
    "\n",
    "    # Calculate new dimensions\n",
    "    new_height = tf.cast(tf.math.round(original_height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.round(original_width * scale), tf.int32)\n",
    "\n",
    "    # Resize the image while maintaining aspect ratio\n",
    "    resized_img = tf.image.resize(img, [new_height, new_width], method='bilinear')\n",
    "\n",
    "    # Use resize_with_pad to add padding to make the image square\n",
    "    padded_img = tf.image.resize_with_pad(\n",
    "        resized_img, \n",
    "        TARGET_SIZE, \n",
    "        TARGET_SIZE, \n",
    "        method='bilinear'\n",
    "    )\n",
    "\n",
    "    img_arr = img_to_array(padded_img)\n",
    "    images.append(img_arr)\n",
    "\n",
    "    # Append the class to the list of labels\n",
    "    labels.append(row[\"class_idx\"])\n",
    "\n",
    "    {label: train_labels_class.count(label) for label in set(train_labels_class)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7663916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_augmentation(X):\n",
    "    random_number = random.randint(1, 4)\n",
    "\n",
    "    if random_number == 1:\n",
    "        return tf.image.flip_left_right(X)\n",
    "    if random_number == 2:\n",
    "        return tf.image.flip_up_down(X)\n",
    "    if random_number == 3:\n",
    "        return tf.image.adjust_brightness(X, delta=0.3)\n",
    "    if random_number == 4:\n",
    "        return tf.image.adjust_contrast(X, contrast_factor=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "for class_label, label_count in label_counts.items():\n",
    "    # The number of images that need to be augmented and appended to reach 1000\n",
    "    images_to_augment = 1000 - label_count\n",
    "    \n",
    "    # Pool of potential images to augment\n",
    "    image_pool_idx = [i for i, label in enumerate(labels) if label == class_label]\n",
    "\n",
    "    for i in range(images_to_augment):\n",
    "\n",
    "        # Select a random image to augment\n",
    "        image_idx = random.choice(image_pool_idx)\n",
    "        image_to_aug = images[image_idx]\n",
    "\n",
    "        # Apply a random augmentation\n",
    "        augmented = apply_random_augmentation(image_to_aug)\n",
    "\n",
    "        # Save new image and label\n",
    "        augmented_images.append(augmented)\n",
    "        augmented_labels.append(class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faba7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to the existing\n",
    "images = images + augmented_images\n",
    "labels = labels + augmented_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80729622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack and convert into a numpy array\n",
    "images = np.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf5876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale all of the images so they're pixel value is between [0, 1]\n",
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec831680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast label list to np.array for easier manipulation\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e171f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-split the images and their labels\n",
    "train_idx = md_df[\"split\"] == \"train\"\n",
    "val_idx = md_df[\"split\"] == \"val\"\n",
    "test_idx = md_df[\"split\"] == \"test\"\n",
    "\n",
    "train_images = images[train_idx]\n",
    "train_labels = labels[train_idx]\n",
    "\n",
    "val_images = images[val_idx]\n",
    "val_labels = labels[val_idx]\n",
    "\n",
    "test_images = images[test_idx]\n",
    "test_labels = labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd12af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape train images: {train_images.shape}\")\n",
    "print(f\"Shape val images: {val_images.shape}\")\n",
    "print(f\"Shape test images: {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_AS = Path(\"./balanced_classes\")\n",
    "SAVE_AS.mkdir(exist_ok=True)\n",
    "\n",
    "# Save the image data\n",
    "np.save(SAVE_AS / \"train_images.npy\", train_images)\n",
    "np.save(SAVE_AS / \"val_images.npy\", val_images)\n",
    "np.save(SAVE_AS / \"test_images.npy\", test_images)\n",
    "\n",
    "# Save the label data\n",
    "np.save(SAVE_AS / \"train_labels.npy\", train_labels)\n",
    "np.save(SAVE_AS / \"val_labels.npy\", val_labels)\n",
    "np.save(SAVE_AS / \"test_labels.npy\", test_labels)\n",
    "\n",
    "# Save the  metadata\n",
    "md_df.to_csv(SAVE_AS / \"metadata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca4065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
