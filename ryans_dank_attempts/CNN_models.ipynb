{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df35d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "\n",
    "# tf and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from PIL import ImageFile\n",
    "\n",
    "# sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df06cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a bunch of functions to load the data\n",
    "\n",
    "def load_metadata(metadata_path='fungi-clef-2025/metadata/FungiTastic-FewShot/', image_path='fungi-clef-2025/images/FungiTastic-FewShot/'):   # Load the metadata for each data split\n",
    "    \"\"\"Load the metadata for each data split.\"\"\"\n",
    "    # Load the metadata for each split\n",
    "    train_metadata = pd.read_csv(os.path.join(metadata_path, 'FungiTastic-FewShot-Train.csv'))\n",
    "    test_metadata = pd.read_csv(os.path.join(metadata_path, 'FungiTastic-FewShot-Val.csv'))\n",
    "\n",
    "    train_metadata = train_metadata.dropna(subset=[\"class\"])\n",
    "    train_metadata = train_metadata.groupby('class').filter(lambda x: len(x) > 1)\n",
    "\n",
    "    train_metadata, val_metadata = train_test_split(train_metadata, test_size=0.2, stratify=train_metadata[\"class\"])\n",
    "    \n",
    "    # Label each split\n",
    "    train_metadata[\"split\"] = \"train\"\n",
    "    val_metadata[\"split\"] = \"val\"\n",
    "    test_metadata[\"split\"] = \"test\"\n",
    "\n",
    "    # Join all of the data together\n",
    "    df_metadata = pd.concat([train_metadata, val_metadata, test_metadata])\n",
    "\n",
    "    # Add the full image location for each image\n",
    "    # Options for image size include 300p, 500p, 720p, fullsize \n",
    "    for idx, row in df_metadata.iterrows():\n",
    "        if row[\"split\"] in [\"train\", \"val\"]:\n",
    "            path = os.path.join(image_path, f\"train/300p/{row['filename']}\")\n",
    "        else:\n",
    "            path = os.path.join(image_path, f\"val/300p/{row['filename']}\")\n",
    "        df_metadata.at[idx, \"image_path\"] = path\n",
    "\n",
    "    return df_metadata\n",
    "\n",
    "\n",
    "def mapping(df, label):   # Map the labels to integers\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[label])\n",
    "    df[label + \"_label\"] = df[label]\n",
    "    df[label + \"_idx\"] = le.transform(df[label])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_random_augmentation(X):   # Apply random augmentation to the image\n",
    "    random_number = random.randint(1, 4)\n",
    "\n",
    "    if random_number == 1:\n",
    "        return tf.image.flip_left_right(X)\n",
    "    if random_number == 2:\n",
    "        return tf.image.flip_up_down(X)\n",
    "    if random_number == 3:\n",
    "        return tf.image.adjust_brightness(X, delta=0.3)\n",
    "    if random_number == 4:\n",
    "        return tf.image.adjust_contrast(X, contrast_factor=3)\n",
    "\n",
    "\n",
    "def preprocess_image_tf(image, target_size):   # Preprocess the image keeping the aspect ratio\n",
    "    # Load image using designated filepath\n",
    "    img = load_img(image)\n",
    "\n",
    "    # Get original dimensions\n",
    "    original_height = tf.cast(tf.shape(img)[0], tf.float32)\n",
    "    original_width = tf.cast(tf.shape(img)[1], tf.float32)\n",
    "    \n",
    "    # Calculate scaling factor to maintain aspect ratio\n",
    "    height_scale = target_size / original_height\n",
    "    width_scale = target_size / original_width\n",
    "    scale = tf.minimum(height_scale, width_scale)\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_height = tf.cast(tf.math.round(original_height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.round(original_width * scale), tf.int32)\n",
    "    \n",
    "    # Resize the image while maintaining aspect ratio\n",
    "    resized_img = tf.image.resize(img, [new_height, new_width], method='bilinear')\n",
    "    \n",
    "    # Use resize_with_pad to add padding to make the image square\n",
    "    padded_img = tf.image.resize_with_pad(\n",
    "        resized_img, \n",
    "        target_size, \n",
    "        target_size, \n",
    "        method='bilinear'\n",
    "    )\n",
    "    \n",
    "    # Normalize pixel values to [0,1]\n",
    "    normalized_img = tf.cast(padded_img, tf.float32) / 255.0\n",
    "    \n",
    "    return normalized_img\n",
    "\n",
    "\n",
    "def load_images_and_labels(df, image_size):   # Load the images and labels based on the metadata\n",
    "    \"\"\"Load the images and labels based on the metadata frame passed in.\"\"\"\n",
    "    images = []\n",
    "    labels_class = []\n",
    "    # labels_poison = []\n",
    "    # labels_species = []\n",
    "    variables = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        # Load and save the image as an array\n",
    "        # img = load_img(row[\"image_path\"], target_size=image_size)\n",
    "        img = preprocess_image_tf(row[\"image_path\"], image_size)\n",
    "        img_arr = img_to_array(img)\n",
    "        images.append(img_arr)\n",
    "\n",
    "        # Append the class to the list of labels\n",
    "        labels_class.append(row[\"class_idx\"])\n",
    "\n",
    "        # labels_poison.append(row[\"poisonous\"])\n",
    "        # labels_species.append(row[\"species_idx\"])\n",
    "        # variables.append((row[\"latitude\"], row[\"longitude\"], row[\"elevation\"], row[\"countryCode\"], row[\"region\"], row[\"substrate\"], row[\"habitat\"], row[\"landcover\"]))\n",
    "        variables.append((row[\"elevation\"], row[\"habitat\"]))\n",
    "\n",
    "    # Stack and convert into a numpy array\n",
    "    images = np.stack(images)\n",
    "\n",
    "    # Cast label list to np.array for easier manipulation\n",
    "    labels_class = np.array(labels_class)\n",
    "    # labels_poison = np.array(labels_poison)\n",
    "    # labels_species = np.array(labels_species)\n",
    "    variables = np.array(variables)\n",
    "\n",
    "    return images, labels_class, variables #, labels_poison, labels_species, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b9f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3322b569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "028897ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_df = load_metadata()\n",
    "\n",
    "md_df = mapping(md_df, \"class\")\n",
    "\n",
    "images, labels_class, variables = load_images_and_labels(md_df, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d69af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-split the images and their labels\n",
    "train_idx = md_df[\"split\"] == \"train\"\n",
    "val_idx = md_df[\"split\"] == \"val\"\n",
    "test_idx = md_df[\"split\"] == \"test\"\n",
    "\n",
    "train_images = images[train_idx]\n",
    "train_labels_class = labels_class[train_idx]\n",
    "# train_labels_poison = labels_poison[train_idx]\n",
    "# train_labels_species = labels_species[train_idx]\n",
    "train_variables = variables[train_idx]\n",
    "\n",
    "val_images = images[val_idx]\n",
    "val_labels_class = labels_class[val_idx]\n",
    "# val_labels_poison = labels_poison[val_idx]\n",
    "# val_labels_species = labels_species[val_idx]\n",
    "val_variables = variables[val_idx]\n",
    "\n",
    "test_images = images[test_idx]\n",
    "test_labels_class = labels_class[test_idx]\n",
    "# test_labels_poison = labels_poison[test_idx]\n",
    "# test_labels_species = labels_species[test_idx]\n",
    "test_variables = variables[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = {label: np.sum(train_labels_class == label) for label in np.unique(train_labels_class)}   # Count the number of images per class\n",
    "\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "augmented_variables = []\n",
    "\n",
    "for class_label, label_count in label_counts.items():   # Iterate through each class and its count\n",
    "    # The number of images that need to be augmented or removed to reach the target\n",
    "    images_to_augment = 600 - label_count\n",
    "\n",
    "    if images_to_augment < 0:\n",
    "        # Remove excess images if there are too many for this class\n",
    "        images_to_remove = abs(images_to_augment)\n",
    "        \n",
    "        # Get indices of images belonging to this class\n",
    "        image_pool_idx = [i for i, label in enumerate(train_labels_class) if label == class_label]\n",
    "        \n",
    "        # Randomly select indices to remove\n",
    "        indices_to_remove = random.sample(image_pool_idx, images_to_remove)\n",
    "        \n",
    "        # Remove the selected images, labels, and variables\n",
    "        train_images = np.delete(train_images, indices_to_remove, axis=0)\n",
    "        train_labels_class = np.delete(train_labels_class, indices_to_remove, axis=0)\n",
    "        train_variables = np.delete(train_variables, indices_to_remove, axis=0)\n",
    "        \n",
    "        continue  # Skip augmentation for this class\n",
    "\n",
    "    elif images_to_augment > 0:\n",
    "        # Pool of potential images to augment\n",
    "        image_pool_idx = [i for i, label in enumerate(train_labels_class) if label == class_label]\n",
    "\n",
    "        for i in range(images_to_augment):\n",
    "            # Select a random image to augment\n",
    "            image_idx = random.choice(image_pool_idx)\n",
    "            image_to_aug = train_images[image_idx]\n",
    "            variables_to_aug = train_variables[image_idx]  # Get the associated metadata\n",
    "\n",
    "            # Apply a random augmentation\n",
    "            augmented = apply_random_augmentation(image_to_aug)\n",
    "\n",
    "            # Normalize the augmented image to ensure it's between 0 and 1\n",
    "            augmented = tf.clip_by_value(augmented, 0.0, 1.0).numpy()  # Clip values to [0, 1]\n",
    "\n",
    "            # Save new image, label, and metadata\n",
    "            augmented_images.append(augmented)\n",
    "            augmented_labels.append(class_label)\n",
    "            augmented_variables.append(variables_to_aug)\n",
    "\n",
    "# Add augmented images to the existing dataset\n",
    "train_images = np.concatenate((train_images, np.array(augmented_images)), axis=0)\n",
    "train_labels_class = np.concatenate((train_labels_class, np.array(augmented_labels)), axis=0)\n",
    "train_variables = np.concatenate((train_variables, np.array(augmented_variables)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac6e12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd1a9995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train images: (18000, 224, 224, 3)\n",
      "Shape train classes: (18000,)\n",
      "Shape train variables: (18000, 2)\n",
      "Shape val images: (1556, 224, 224, 3)\n",
      "Shape test images: (2285, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape train images: {train_images.shape}\")\n",
    "print(f\"Shape train classes: {train_labels_class.shape}\")\n",
    "# print(f\"Shape train poison: {train_labels_poison.shape}\")\n",
    "# print(f\"Shape train species: {train_labels_species.shape}\")\n",
    "print(f\"Shape train variables: {train_variables.shape}\")\n",
    "print(f\"Shape val images: {val_images.shape}\")\n",
    "print(f\"Shape test images: {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5df97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training images\n",
    "indices = list(range(train_images.shape[0]))  # create a list of indices of the size of the dataset\n",
    "\n",
    "shuffled_indices = np.random.permutation(indices)  # shuffle the indices\n",
    "\n",
    "train_images_shuffled = train_images[shuffled_indices]  # shuffle the rows of the dataset\n",
    "train_labels_class_shuffled = train_labels_class[shuffled_indices]\n",
    "# train_labels_poison_shuffled = train_labels_poison[shuffled_indices]\n",
    "# train_labels_species_shuffled = train_labels_species[shuffled_indices]\n",
    "train_variables_shuffled = train_variables[shuffled_indices]\n",
    "\n",
    "\n",
    "# Shuffle the validation images\n",
    "indices = list(range(val_images.shape[0]))  # create a list of indices of the size of the dataset\n",
    "shuffled_indices = np.random.permutation(indices)  # shuffle the indices\n",
    "val_images_shuffled = val_images[shuffled_indices]  # shuffle the rows of the dataset\n",
    "val_labels_class_shuffled = val_labels_class[shuffled_indices]\n",
    "# val_labels_poison_shuffled = val_labels_poison[shuffled_indices]\n",
    "# val_labels_species_shuffled = val_labels_species[shuffled_indices]\n",
    "val_variables_shuffled = val_variables[shuffled_indices]\n",
    "\n",
    "\n",
    "# Shuffle the test images\n",
    "indices = list(range(test_images.shape[0]))  # create a list of indices of the size of the dataset\n",
    "shuffled_indices = np.random.permutation(indices)  # shuffle the indices\n",
    "test_images_shuffled = test_images[shuffled_indices]  # shuffle the rows of the dataset\n",
    "test_labels_class_shuffled = test_labels_class[shuffled_indices]\n",
    "# test_labels_poison_shuffled = test_labels_poison[shuffled_indices]\n",
    "# test_labels_species_shuffled = test_labels_species[shuffled_indices]\n",
    "test_variables_shuffled = test_variables[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cfb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add some data augmentation!\n",
    "# # Some horizontal flips? Random crops?\n",
    "\n",
    "# def data_preprocessing(X, labels_class, labels_variables, data_partition='train'):\n",
    "#     '''Apply transformations and augmentations to training, validation, and test data;'''\n",
    "\n",
    "#     CONTRAST_FACTOR = 3\n",
    "#     DELTA = 0.3\n",
    "    \n",
    "#     # image augmentation on training data\n",
    "#     if data_partition==\"train\":\n",
    "#         # adjust brightness\n",
    "#         X_augm = tf.image.adjust_brightness(X, delta=DELTA) # FILL IN CODE HERE #\n",
    "\n",
    "#         # adjust contrast\n",
    "#         X_augm = tf.image.adjust_contrast(X_augm, contrast_factor=CONTRAST_FACTOR) # FILL IN CODE HERE #\n",
    "\n",
    "#         # random flip\n",
    "#         X_augm = tf.image.flip_left_right(X_augm) # FILL IN CODE HERE #\n",
    "\n",
    "#         # concatenate original X and augmented X_aug data\n",
    "#         X = tf.concat([X, X_augm],axis=0) # FILL IN CODE HERE #\n",
    "\n",
    "#         # concatenate y_train (note the label is preserved)\n",
    "#         labels_class_augm = labels_class\n",
    "#         labels_class = tf.concat([labels_class, labels_class_augm],axis=0)\n",
    "\n",
    "#         # labels_poison_augm = labels_poison\n",
    "#         # labels_poison = tf.concat([labels_poison, labels_poison_augm],axis=0)\n",
    "\n",
    "#         # labels_species_augm = labels_species\n",
    "#         # labels_species = tf.concat([labels_species, labels_species_augm],axis=0)\n",
    "\n",
    "#         labels_variables_augm = labels_variables\n",
    "#         labels_variables = tf.concat([labels_variables, labels_variables_augm],axis=0)\n",
    "\n",
    "#         # shuffle X and y, i.e., shuffle two tensors in the same order\n",
    "#         shuffle = tf.random.shuffle(tf.range(tf.shape(X)[0], dtype=tf.int32))\n",
    "#         X = tf.gather(X, shuffle).numpy() # transform X back to numpy array instead of tensor\n",
    "#         labels_class = tf.gather(labels_class, shuffle).numpy() # transform y back to numpy array instead of tensor\n",
    "#         # labels_poison = tf.gather(labels_poison, shuffle).numpy()\n",
    "#         # labels_species = tf.gather(labels_species, shuffle).numpy()\n",
    "#         labels_variables = tf.gather(labels_variables, shuffle).numpy()\n",
    "        \n",
    "        \n",
    "#     # rescale image by dividing each pixel by 255.0 \n",
    "#     # FILL IN CODE HERE #\n",
    "#     X = X / 255.0\n",
    "    \n",
    "#     return X, labels_class, labels_variables #, labels_poison, labels_species, labels_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388a330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # apply data preprocessing\n",
    "# train_images_shuffled, train_labels_class_shuffled, train_variables_shuffled = data_preprocessing(train_images_shuffled, train_labels_class_shuffled, train_variables_shuffled, data_partition='train')\n",
    "# val_images_shuffled, val_labels_class_shuffled, val_variables_shuffled = data_preprocessing(val_images_shuffled, val_labels_class_shuffled, val_variables_shuffled, data_partition='val')\n",
    "# test_images_shuffled, test_labels_class_shuffled, test_variables_shuffled = data_preprocessing(test_images_shuffled, test_labels_class_shuffled, test_variables_shuffled, data_partition='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de23ca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train images  (18000, 224, 224, 3)\n",
      "Shape of train labels  (18000,)\n",
      "Shape of val images  (1556, 224, 224, 3)\n",
      "Shape of val labels  (1556,)\n",
      "Shape of test images  (2285, 224, 224, 3)\n",
      "Shape of test labels  (2285,)\n"
     ]
    }
   ],
   "source": [
    "# print shapes\n",
    "print('Shape of train images ', train_images_shuffled.shape)\n",
    "print('Shape of train labels ', train_labels_class_shuffled.shape)\n",
    "print('Shape of val images ', val_images_shuffled.shape)\n",
    "print('Shape of val labels ', val_labels_class_shuffled.shape)\n",
    "print('Shape of test images ', test_images_shuffled.shape)\n",
    "print('Shape of test labels ', test_labels_class_shuffled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57342f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "[ 0  1  3  4  6  7  9 10 11 13 14 15 17 18 19 20 21 22 23 25 26 27 28 30]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_labels_class_shuffled))\n",
    "print(np.unique(val_labels_class_shuffled))\n",
    "print(np.unique(test_labels_class_shuffled))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd1f6ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered test images shape: (2275, 224, 224, 3)\n",
      "Filtered test labels shape: (2275,)\n",
      "Unique test labels: [ 0  1  3  4  6  7  9 10 11 13 14 15 17 18 19 20 21 22 23 25 26 27 28]\n"
     ]
    }
   ],
   "source": [
    "# Filter out invalid labels from the test data\n",
    "valid_indices = test_labels_class_shuffled < 30  # Keep only labels less than 30\n",
    "\n",
    "# Apply the filter to both images and labels\n",
    "test_images_shuffled = test_images_shuffled[valid_indices]\n",
    "test_labels_class_shuffled = test_labels_class_shuffled[valid_indices]\n",
    "test_variables_shuffled = test_variables_shuffled[valid_indices]\n",
    "\n",
    "# Verify the result\n",
    "print(f\"Filtered test images shape: {test_images_shuffled.shape}\")\n",
    "print(f\"Filtered test labels shape: {test_labels_class_shuffled.shape}\")\n",
    "print(f\"Unique test labels: {np.unique(test_labels_class_shuffled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3769930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">401408</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,042,270</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m401408\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │    \u001b[38;5;34m12,042,270\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,043,838</span> (45.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,043,838\u001b[0m (45.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,043,838</span> (45.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,043,838\u001b[0m (45.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Basic CNN model\n",
    "\n",
    "# Set a random seed and clear back end\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# Convolutional Layer\n",
    "conv_layer = tf.keras.layers.Conv2D(32, kernel_size=4, padding=\"same\", activation=\"relu\")\n",
    "\n",
    "# Pooling Layer\n",
    "pooling_layer = tf.keras.layers.MaxPool2D()\n",
    "\n",
    "# Dropout Layer\n",
    "dropout_layer = tf.keras.layers.Dropout(0.25)\n",
    "\n",
    "# Flattening\n",
    "flat_layer = tf.keras.layers.Flatten()\n",
    "\n",
    "# Dense (Multiclassification Layer)\n",
    "num_classes = len(set(train_labels_class_shuffled))\n",
    "softmax_layer = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    conv_layer,\n",
    "    pooling_layer,\n",
    "    dropout_layer,\n",
    "    flat_layer,\n",
    "    softmax_layer\n",
    "])\n",
    "\n",
    "# build and compile model\n",
    "model_1.build(input_shape=(None, 224, 224, 3))\n",
    "\n",
    "model_1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# print model_tf summary\n",
    "### YOUR CODE HERE ###\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5318aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71337b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_shuffled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d601b8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">401408</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,042,270</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m401408\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │    \u001b[38;5;34m12,042,270\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,043,838</span> (45.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,043,838\u001b[0m (45.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,043,838</span> (45.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,043,838\u001b[0m (45.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9224266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 190ms/step - accuracy: 0.0346 - loss: 9.1473 - val_accuracy: 0.0019 - val_loss: 3.4012\n",
      "Epoch 2/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 200ms/step - accuracy: 0.0339 - loss: 3.4012 - val_accuracy: 0.0019 - val_loss: 3.4012\n",
      "Epoch 3/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 212ms/step - accuracy: 0.0339 - loss: 3.4012 - val_accuracy: 0.0019 - val_loss: 3.4012\n",
      "Epoch 4/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 219ms/step - accuracy: 0.0339 - loss: 3.4012 - val_accuracy: 0.0019 - val_loss: 3.4012\n",
      "Epoch 5/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 219ms/step - accuracy: 0.0339 - loss: 3.4012 - val_accuracy: 0.0019 - val_loss: 3.4012\n",
      "Epoch 6/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 219ms/step - accuracy: 0.0339 - loss: 3.4012 - val_accuracy: 0.0019 - val_loss: 3.4012\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Total params:  12043838\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.03333333507180214\n",
      "Validation Accuracy: 0.0019280206179246306\n"
     ]
    }
   ],
   "source": [
    "# train model_tf on (X_train, y_train) data\n",
    "### YOUR CODE HERE ###\n",
    "history = model_1.fit(train_images_shuffled, train_labels_class_shuffled, epochs=10, validation_data=(val_images_shuffled, val_labels_class_shuffled), callbacks=[early_stopping])\n",
    "print('Total params: ', model_1.count_params())\n",
    "\n",
    "# plot loss curves\n",
    "### YOUR CODE HERE ###\n",
    "trained_model_epochs = history.history\n",
    "x_arr = np.arange(len(trained_model_epochs['loss'])) + 1 \n",
    "plt.plot(x_arr, trained_model_epochs['loss'], '-o', label='Train loss')\n",
    "plt.plot(x_arr, trained_model_epochs['val_loss'], '--<', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# evaluate the accuracy of model_tf on (X_train, y_train) and (X_val, y_val)\n",
    "### YOUR CODE HERE ###\n",
    "print('Training Accuracy:', trained_model_epochs['accuracy'][-1])\n",
    "print('Validation Accuracy:', trained_model_epochs['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64879a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the training metrics (after each train epoch) and the final validation\n",
    "# accuracy.\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "plt.plot(train_accuracy, label='train_accuracy')\n",
    "plt.plot(val_accuracy, label='validation accuracy')\n",
    "plt.xlabel('Train epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Training accuracy: %1.4f' %train_accuracy[-1])\n",
    "print('Validation accuracy: %1.4f' %val_accuracy[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06fd6e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.0000e+00 - loss: 3.4012\n",
      "Test Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy:', model_1.evaluate(test_images_shuffled, test_labels_class_shuffled)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab739779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">802816</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,084,510</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_1 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_2 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m802816\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │    \u001b[38;5;34m24,084,510\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,118,910</span> (92.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,118,910\u001b[0m (92.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,118,910</span> (92.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,118,910\u001b[0m (92.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1184s\u001b[0m 2s/step - accuracy: 0.0342 - loss: 5714.0376 - val_accuracy: 0.0488 - val_loss: 3.3511\n",
      "Epoch 2/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1230s\u001b[0m 2s/step - accuracy: 0.0339 - loss: 3.4220 - val_accuracy: 0.0488 - val_loss: 3.3487\n",
      "Epoch 3/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8757s\u001b[0m 16s/step - accuracy: 0.0337 - loss: 3.4226 - val_accuracy: 0.0488 - val_loss: 3.3483\n",
      "Epoch 4/10\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8657s\u001b[0m 15s/step - accuracy: 0.0339 - loss: 3.4229 - val_accuracy: 0.0488 - val_loss: 3.3483\n",
      "Epoch 5/10\n",
      "\u001b[1m140/563\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:02\u001b[0m 2s/step - accuracy: 0.0333 - loss: 3.4221"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_2\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# train model_tf on (X_train, y_train) data\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m### YOUR CODE HERE ###\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m model_2\u001b[38;5;241m.\u001b[39mfit(train_images_shuffled, train_labels_class_shuffled, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(val_images_shuffled, val_labels_class_shuffled), callbacks\u001b[38;5;241m=\u001b[39m[early_stopping])\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal params: \u001b[39m\u001b[38;5;124m'\u001b[39m, model_2\u001b[38;5;241m.\u001b[39mcount_params())\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# plot loss curves\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m### YOUR CODE HERE ###\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1689\u001b[0m   )\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize more complext CNN model\n",
    "model_2 = tf.keras.Sequential()\n",
    "\n",
    "# add convolutional layer\n",
    "### YOUR CODE HERE ###\n",
    "model_2.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(4,4), strides=(1,1), padding='same', name='conv_1', activation='relu'))\n",
    "model_2.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(4,4), strides=(1,1), padding='same', name='conv_2', activation='relu'))\n",
    "\n",
    "# add max pooling layer \n",
    "### YOUR CODE HERE ###\n",
    "model_2.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# add dropout layer\n",
    "### YOUR CODE HERE ###\n",
    "model_2.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "# add a flattening layer\n",
    "### YOUR CODE HERE ###\n",
    "model_2.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# add the classification layer\n",
    "### YOUR CODE HERE ###\n",
    "num_classes = len(set(train_labels_class_shuffled))\n",
    "model_2.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# build and compile model\n",
    "model_2.build(input_shape=(None, 224, 224, 3))\n",
    "model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# print model_tf summary\n",
    "### YOUR CODE HERE ###\n",
    "print(model_2.summary())\n",
    "\n",
    "# train model_tf on (X_train, y_train) data\n",
    "### YOUR CODE HERE ###\n",
    "trained_model = model_2.fit(train_images_shuffled, train_labels_class_shuffled, epochs=10, validation_data=(val_images_shuffled, val_labels_class_shuffled), callbacks=[early_stopping])\n",
    "print('Total params: ', model_2.count_params())\n",
    "\n",
    "# plot loss curves\n",
    "### YOUR CODE HERE ###\n",
    "trained_model_epochs = trained_model.history\n",
    "x_arr = np.arange(len(trained_model_epochs['loss'])) + 1 \n",
    "plt.plot(x_arr, trained_model_epochs['loss'], '-o', label='Train loss')\n",
    "plt.plot(x_arr, trained_model_epochs['val_loss'], '--<', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# evaluate the accuracy of model_tf on (X_train, y_train) and (X_val, y_val)\n",
    "### YOUR CODE HERE ###\n",
    "print('Training Accuracy:', trained_model_epochs['accuracy'][-1])\n",
    "print('Validation Accuracy:', trained_model_epochs['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the training metrics (after each train epoch) and the final validation\n",
    "# accuracy.\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "plt.plot(train_accuracy, label='train_accuracy')\n",
    "plt.plot(val_accuracy, label='validation accuracy')\n",
    "plt.xlabel('Train epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Training accuracy: %1.4f' %train_accuracy[-1])\n",
    "print('Validation accuracy: %1.4f' %val_accuracy[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc42f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 323ms/step - accuracy: 0.0215 - loss: 3.3924\n",
      "Test Accuracy: 0.024175824597477913\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('Test Accuracy:', model_2.evaluate(test_images_shuffled, test_labels_class_shuffled)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682595c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
